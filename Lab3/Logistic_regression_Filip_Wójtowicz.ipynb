{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    " \n",
    "import os\n",
    "path = os.getcwd() + '/ex2data1.txt'\n",
    "data = pd.read_csv(path, header=None, names=['Exam 1', 'Exam 2', 'Admitted'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example 0:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Right there I use different functions that I learned earlier, to get familiar with the data\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_new = (data - data.mean())/data.std()  # performing 'feature normalization' (I won't use normalized y!!!)\n",
    "data_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example 1:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.insert(0, '1s', 1)  # with function 'insert' I added column of 1s at the beginning\n",
    "data_new.insert(0, '1s', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data[['1s', 'Exam 1', 'Exam 2']]\n",
    "y = data['Admitted']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(X.values).T  # changing to numpy\n",
    "y = np.array(y.values, dtype=float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example 2:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta = np.zeros(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the data\n",
    "admitted = []\n",
    "not_admitted = []\n",
    "for i in range(X.shape[1]):\n",
    "    if y[i] == 1:\n",
    "        admitted.append(X[1:, i])\n",
    "    else:\n",
    "        not_admitted.append(X[1:, i])\n",
    "admitted = np.array(admitted)\n",
    "not_admitted = np.array(not_admitted)\n",
    "\n",
    "plt.figure(figsize=(20, 10))\n",
    "'''fig, ax = plt.subplots()\n",
    "fig.set_size_inches(20, 10)\n",
    "\n",
    "plt.scatter(X.T[:, 1], X.T[:, 2], c=y)'''\n",
    "plt.scatter(admitted[:, 0], admitted[:, 1], color='green', label='admitted')\n",
    "plt.scatter(not_admitted[:, 0], not_admitted[:, 1], color='red', label='not admitted')\n",
    "plt.xlabel('Iteration number')\n",
    "plt.ylabel('Cost function value')\n",
    "plt.legend(loc='upper right')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example 3:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implemented logistic function \n",
    "def sig(t):\n",
    "    out = 1/(1 + np.exp(-t))\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example 4:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the results of written function\n",
    "test = np.arange(-5, 5, 0.5)\n",
    "result = sig(test)\n",
    "\n",
    "plt.plot(test, result)\n",
    "plt.xlabel('Iteration number')\n",
    "plt.ylabel('Cost function value')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example 5:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implemented vectorized function 'cost'\n",
    "def cost(theta_p, X_p, y_p):\n",
    "    m = y_p.shape[0]\n",
    "    h = sig(theta_p@X_p)\n",
    "    y_0 = -(1 - y_p.T)@(np.log(1 - h)).T\n",
    "    y_1 = -y_p.T@(np.log(h)).T\n",
    "    c = (y_1 + y_0)/m\n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta = np.zeros(3)\n",
    "\n",
    "cost(theta, X, y)  # quick chceck of the outcome"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example 6:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implemented simple gradient function\n",
    "def simple_gradient(X_p, y_p, theta_p, alpha_p, it_p):\n",
    "    # it - iteration nb.\n",
    "    m = y_p.shape[0]\n",
    "    costs = 0\n",
    "    for i in range(it_p):\n",
    "        h = sig(theta_p@X_p)\n",
    "        theta_p = theta_p - alpha_p*((h - y_p)@X_p.T)/m\n",
    "        costs = cost(theta_p, X_p, y_p)\n",
    "    return theta_p, costs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing data to execute the function\n",
    "alpha = 1\n",
    "it = 150\n",
    "theta = np.zeros(3)\n",
    "\n",
    "X_new = data_new[['1s', 'Exam 1', 'Exam 2']]\n",
    "X_new = np.array(X_new.values).T\n",
    "\n",
    "theta_new, final_cost = simple_gradient(X_new, y, theta, alpha, it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta_new  # new theta values, calculated by simple_gradient function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_cost  # final cost, calculated by simple_gradient function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example 7:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = (sig(theta_new@X_new) >= 0.5).astype(int)  # applying threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison = np.array([y[i] == result[i] for i in range(y.shape[0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison  # True means, that the prediction was correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = len(comparison[comparison != False])/len(comparison)  # final accuracy of the algorithm\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example 8:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating coefficients for regression\n",
    "c = -theta_new[0]/theta_new[2]\n",
    "m = -theta_new[1]/theta_new[2]\n",
    "\n",
    "boundary = m*X_new.T[:, 1] + c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the data with regression \n",
    "admitted = []\n",
    "not_admitted = []\n",
    "for i in range(X.shape[1]):\n",
    "    if y[i] == 1:\n",
    "        admitted.append(X_new[1:, i])\n",
    "    else:\n",
    "        not_admitted.append(X_new[1:, i])\n",
    "admitted = np.array(admitted)\n",
    "not_admitted = np.array(not_admitted)\n",
    "\n",
    "plt.figure(figsize=(20, 10))\n",
    "#fig, ax = plt.subplots()\n",
    "#fig.set_size_inches(20, 10)\n",
    "\n",
    "plt.scatter(admitted[:, 0], admitted[:, 1], color='green', label='admitted')\n",
    "plt.scatter(not_admitted[:, 0], not_admitted[:, 1], color='red', label='not admitted')\n",
    "plt.plot(X_new.T[:, 1], boundary)\n",
    "plt.xlabel('Iteration number')\n",
    "plt.ylabel('Cost function value')\n",
    "plt.legend(loc='upper right')\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic regression - Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    " \n",
    "iris = datasets.load_iris()\n",
    "X = iris.data[:, :2]  # we are analyzing only 2 parameters\n",
    "Y = iris.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example 1, 2:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogisticRegression(C=10.0)  # I use there default optimalization algorithm, with regularization coefficient \n",
    "                                    # equal to 10 (best outcome)                \n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3)  # split the data to train and test dataset\n",
    "\n",
    "logreg.fit(X_train, Y_train)  # train the model\n",
    "Y_predicted = logreg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the decision boundary. For that, we will assign a color to each\n",
    "# point in the mesh [x_min, x_max]x[y_min, y_max].\n",
    "x_min, x_max = X[:, 0].min() - .5, X[:, 0].max() + .5\n",
    "y_min, y_max = X[:, 1].min() - .5, X[:, 1].max() + .5\n",
    "h = .02  # step size in the mesh\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "Z = logreg.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    " \n",
    "# Put the result into a color plot\n",
    "Z = Z.reshape(xx.shape)\n",
    "plt.figure(1, figsize=(10, 8))\n",
    "plt.pcolormesh(xx, yy, Z, cmap=plt.cm.Paired)\n",
    " \n",
    "# Plot also the training points\n",
    "plt.scatter(X[:, 0], X[:, 1], c=Y, edgecolors='k', cmap=plt.cm.Paired)\n",
    "plt.xlabel('Sepal length')\n",
    "plt.ylabel('Sepal width')\n",
    " \n",
    "plt.xlim(xx.min(), xx.max())\n",
    "plt.ylim(yy.min(), yy.max())\n",
    "plt.xticks(())\n",
    "plt.yticks(())\n",
    " \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example 3:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = logreg.predict_proba(X_test)  # used function to calculate probability of belonging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bar plot used to compare probabilities\n",
    "plt.figure(figsize=(20, 5))\n",
    "\n",
    "X_len = X_test.shape[0]\n",
    "X_name = np.linspace(1, 45, 45)\n",
    "X_axis = np.arange(X_len)\n",
    "\n",
    "plt.bar(X_axis - 0.3, predict[:, 0], width=0.3, label = 'Class 0')\n",
    "plt.bar(X_axis, predict[:, 1], width=0.3, label = 'Class 1')\n",
    "plt.bar(X_axis + 0.3, predict[:, 2], width=0.3, label = 'Class 2')\n",
    "plt.xticks(X_axis, X_name)\n",
    "plt.xlim(-1, 45)\n",
    "plt.xlabel('Feature')\n",
    "plt.ylabel('Probability of being a member of a given class')\n",
    "plt.legend(loc='upper right')\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example 4:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_squared_error(Y_test, Y_predicted)  # calculated MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_score(Y_test, Y_predicted)  # calculated R2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_absolute_error(Y_test, Y_predicted)  # calculated mean error rate"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
